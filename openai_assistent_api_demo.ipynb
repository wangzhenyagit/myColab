{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojKrqPJvqYTb"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wangzhenyagit/myColab/blob/main/openai_assistent_api_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "Wl2SUPi4N7Rg",
        "outputId": "2bbb3f56-4a09-4a11-ba60-e37dd79c33c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.2.3)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Requirement already satisfied: httpcore in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import json\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
        "\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "Ty9DDFh9sQHe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload a file with an \"assistants\" purpose\n",
        "file = client.files.create(\n",
        "  file=open(\"AutoGen- Enabling Next-Gen LLM Applications via Multi-Agent Conversation.pdf\", \"rb\"),\n",
        "  purpose='assistants'\n",
        ")"
      ],
      "metadata": {
        "id": "sjWgLV2eDM-S"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the file to the assistant\n",
        "assistant = client.beta.assistants.create(\n",
        "  name=\"Paper Analyst\",\n",
        "  instructions=\"You are a paper analysis chatbot. Use your knowledge base to best respond to user queries.\",\n",
        "  model=\"gpt-4-1106-preview\",\n",
        "  tools=[{\"type\": \"retrieval\"}],\n",
        "  file_ids=[file.id]\n",
        ")"
      ],
      "metadata": {
        "id": "1s01k6scUH5w"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thread = client.beta.threads.create()"
      ],
      "metadata": {
        "id": "qGyPLfiA0suR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(thread)"
      ],
      "metadata": {
        "id": "YqnPsTSMg_Nn",
        "outputId": "2ecda3a4-a770-42f3-e845-89178753d80d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thread(id='thread_7XZM8Qdpb8vbKowiEW5BURw3', created_at=1699706096, metadata={}, object='thread')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=\"Who create AutoGen?\"\n",
        ")"
      ],
      "metadata": {
        "id": "_XA-gsOI0yDS"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = client.beta.threads.runs.create(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id\n",
        ")"
      ],
      "metadata": {
        "id": "A9IscD2J0zrT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(run)"
      ],
      "metadata": {
        "id": "j36XQ3D8fFkm",
        "outputId": "55a2c7a1-86f9-433d-a98d-28eed1f2499e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run(id='run_HV5DWHVY7KJtQaDhWVV4328I', assistant_id='asst_mIK5Gb71yb1Iu3PmePtiXOby', cancelled_at=None, completed_at=None, created_at=1699707885, expires_at=1699708485, failed_at=None, file_ids=['file-xpVHErHEAvwvDcy03y36vder'], instructions='You are a paper analysis chatbot. Use your knowledge base to best respond to user queries.', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_7XZM8Qdpb8vbKowiEW5BURw3', tools=[ToolAssistantToolsRetrieval(type='retrieval')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = client.beta.threads.runs.retrieve(\n",
        "  thread_id=thread.id,\n",
        "  run_id=run.id\n",
        ")"
      ],
      "metadata": {
        "id": "ida1QopB0-oS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(run)"
      ],
      "metadata": {
        "id": "wXRUDji9gVAK",
        "outputId": "00185dd2-0978-428d-d8a1-d22d8f1aa00e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run(id='run_HV5DWHVY7KJtQaDhWVV4328I', assistant_id='asst_mIK5Gb71yb1Iu3PmePtiXOby', cancelled_at=None, completed_at=1699707892, created_at=1699707885, expires_at=None, failed_at=None, file_ids=['file-xpVHErHEAvwvDcy03y36vder'], instructions='You are a paper analysis chatbot. Use your knowledge base to best respond to user queries.', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=1699707885, status='completed', thread_id='thread_7XZM8Qdpb8vbKowiEW5BURw3', tools=[ToolAssistantToolsRetrieval(type='retrieval')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = client.beta.threads.messages.list(\n",
        "  thread_id=thread.id\n",
        ")"
      ],
      "metadata": {
        "id": "CiIFk_sq1DEo"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages.model_dump_json"
      ],
      "metadata": {
        "id": "6kC-oEEFb-ML",
        "outputId": "1b23611f-c614-499e-dc13-2fc24eb9157d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BaseModel.model_dump_json of SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_8JE3d7fRX6npmalkMdMrMlTT', assistant_id='asst_mIK5Gb71yb1Iu3PmePtiXOby', content=[MessageContentText(text=Text(annotations=[TextAnnotationFileCitation(end_index=247, file_citation=TextAnnotationFileCitationFileCitation(file_id='file-xpVHErHEAvwvDcy03y36vder', quote='Qingyun Wu† Gagan Bansal∗ Jieyu Zhang± Yiran Wu† Beibin Li∗   Erkang Zhu∗ Li Jiang∗ Xiaoyun Zhang∗ Shaokun Zhang† Jiale Liu∓   Ahmed Awadallah∗ Ryen W. White∗ Doug Burger∗ Chi Wang∗1'), start_index=236, text='【12†source】', type='file_citation')], value='AutoGen was created by a team of researchers, including Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, Ahmed Awadallah, Ryen W. White, Doug Burger, and Chi Wang【12†source】.'), type='text')], created_at=1699707890, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_HV5DWHVY7KJtQaDhWVV4328I', thread_id='thread_7XZM8Qdpb8vbKowiEW5BURw3'), ThreadMessage(id='msg_hb6d8ep2ol3LGTXrl3P5lK6d', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Who create AutoGen?'), type='text')], created_at=1699707865, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_7XZM8Qdpb8vbKowiEW5BURw3'), ThreadMessage(id='msg_jbGtVfui0WE21UuyoM80xP9Q', assistant_id='asst_mIK5Gb71yb1Iu3PmePtiXOby', content=[MessageContentText(text=Text(annotations=[TextAnnotationFileCitation(end_index=849, file_citation=TextAnnotationFileCitationFileCitation(file_id='file-xpVHErHEAvwvDcy03y36vder', quote='AutoGen2 is an open-source framework that allows developers to build LLM ap- plications via multiple agents that can converse with each other to accomplish tasks. AutoGen agents are customizable conversable and can operate in vari- ous modes that employ combinations of LLMs human inputs and tools. Using AutoGen developers can also flexibly define agent interaction behaviors. Both natural language and computer code can be used to program flexible conversation patterns for different applications. AutoGen serves as a generic framework for building diverse applications of various complexities and LLM capacities. Em- pirical studies demonstrate the effectiveness of the framework in many example applications with domains ranging from mathematics coding question answer- ing operations research online decision-making entertainment etc'), start_index=839, text='【7†source】', type='file_citation')], value='AutoGen is an open-source framework that enables developers to create applications using large language models (LLMs) by leveraging multiple agents that can converse with each other to accomplish various tasks. With AutoGen, developers can customize these conversable agents and define their interaction behaviors in flexible ways, employing combinations of LLMs, human inputs, and tools. The framework supports programming these agents using both natural language and computer code to enable conversation patterns suitable for different applications. AutoGen is designed as a generic infrastructure that can accommodate diverse applications, with varying complexities and the capacities of LLMs, covering domains such as mathematics, coding, question answering, operations research, online decision-making, and entertainment, among others【7†source】.'), type='text')], created_at=1699706300, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_f8cudbSlBwMhFjeiwwU6Si4D', thread_id='thread_7XZM8Qdpb8vbKowiEW5BURw3'), ThreadMessage(id='msg_1zpy6SIqU4k1QqMaT9wHRkxA', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='What is AutoGen?'), type='text')], created_at=1699706100, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_7XZM8Qdpb8vbKowiEW5BURw3')], object='list', first_id='msg_8JE3d7fRX6npmalkMdMrMlTT', last_id='msg_1zpy6SIqU4k1QqMaT9wHRkxA', has_more=False)>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages.model_dump"
      ],
      "metadata": {
        "id": "SWsC-oeqcU5k",
        "outputId": "fd6c81a8-3528-459b-cdc5-7eabc4cb3660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BaseModel.model_dump of SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_jbGtVfui0WE21UuyoM80xP9Q', assistant_id='asst_mIK5Gb71yb1Iu3PmePtiXOby', content=[MessageContentText(text=Text(annotations=[TextAnnotationFileCitation(end_index=849, file_citation=TextAnnotationFileCitationFileCitation(file_id='file-xpVHErHEAvwvDcy03y36vder', quote='AutoGen2 is an open-source framework that allows developers to build LLM ap- plications via multiple agents that can converse with each other to accomplish tasks. AutoGen agents are customizable conversable and can operate in vari- ous modes that employ combinations of LLMs human inputs and tools. Using AutoGen developers can also flexibly define agent interaction behaviors. Both natural language and computer code can be used to program flexible conversation patterns for different applications. AutoGen serves as a generic framework for building diverse applications of various complexities and LLM capacities. Em- pirical studies demonstrate the effectiveness of the framework in many example applications with domains ranging from mathematics coding question answer- ing operations research online decision-making entertainment etc'), start_index=839, text='【7†source】', type='file_citation')], value='AutoGen is an open-source framework that enables developers to create applications using large language models (LLMs) by leveraging multiple agents that can converse with each other to accomplish various tasks. With AutoGen, developers can customize these conversable agents and define their interaction behaviors in flexible ways, employing combinations of LLMs, human inputs, and tools. The framework supports programming these agents using both natural language and computer code to enable conversation patterns suitable for different applications. AutoGen is designed as a generic infrastructure that can accommodate diverse applications, with varying complexities and the capacities of LLMs, covering domains such as mathematics, coding, question answering, operations research, online decision-making, and entertainment, among others【7†source】.'), type='text')], created_at=1699706300, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_f8cudbSlBwMhFjeiwwU6Si4D', thread_id='thread_7XZM8Qdpb8vbKowiEW5BURw3'), ThreadMessage(id='msg_1zpy6SIqU4k1QqMaT9wHRkxA', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='What is AutoGen?'), type='text')], created_at=1699706100, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_7XZM8Qdpb8vbKowiEW5BURw3')], object='list', first_id='msg_jbGtVfui0WE21UuyoM80xP9Q', last_id='msg_1zpy6SIqU4k1QqMaT9wHRkxA', has_more=False)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(messages)"
      ],
      "metadata": {
        "id": "EkF7xCqu1EV8",
        "outputId": "ae1e051e-47d7-4050-86c3-9aef98d8514c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_jbGtVfui0WE21UuyoM80xP9Q', assistant_id='asst_mIK5Gb71yb1Iu3PmePtiXOby', content=[MessageContentText(text=Text(annotations=[TextAnnotationFileCitation(end_index=849, file_citation=TextAnnotationFileCitationFileCitation(file_id='file-xpVHErHEAvwvDcy03y36vder', quote='AutoGen2 is an open-source framework that allows developers to build LLM ap- plications via multiple agents that can converse with each other to accomplish tasks. AutoGen agents are customizable conversable and can operate in vari- ous modes that employ combinations of LLMs human inputs and tools. Using AutoGen developers can also flexibly define agent interaction behaviors. Both natural language and computer code can be used to program flexible conversation patterns for different applications. AutoGen serves as a generic framework for building diverse applications of various complexities and LLM capacities. Em- pirical studies demonstrate the effectiveness of the framework in many example applications with domains ranging from mathematics coding question answer- ing operations research online decision-making entertainment etc'), start_index=839, text='【7†source】', type='file_citation')], value='AutoGen is an open-source framework that enables developers to create applications using large language models (LLMs) by leveraging multiple agents that can converse with each other to accomplish various tasks. With AutoGen, developers can customize these conversable agents and define their interaction behaviors in flexible ways, employing combinations of LLMs, human inputs, and tools. The framework supports programming these agents using both natural language and computer code to enable conversation patterns suitable for different applications. AutoGen is designed as a generic infrastructure that can accommodate diverse applications, with varying complexities and the capacities of LLMs, covering domains such as mathematics, coding, question answering, operations research, online decision-making, and entertainment, among others【7†source】.'), type='text')], created_at=1699706300, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_f8cudbSlBwMhFjeiwwU6Si4D', thread_id='thread_7XZM8Qdpb8vbKowiEW5BURw3'), ThreadMessage(id='msg_1zpy6SIqU4k1QqMaT9wHRkxA', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='What is AutoGen?'), type='text')], created_at=1699706100, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_7XZM8Qdpb8vbKowiEW5BURw3')], object='list', first_id='msg_jbGtVfui0WE21UuyoM80xP9Q', last_id='msg_1zpy6SIqU4k1QqMaT9wHRkxA', has_more=False)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "vscode": {
      "interpreter": {
        "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}